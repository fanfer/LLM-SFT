#!/usr/bin/env python3
"""
æ¨¡å‹æ¨ç†ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„é£æ§ç”»åƒæ¨¡å‹è¿›è¡Œä¼ä¸šè¯„ä¼°
"""

import os
import sys
import yaml
import json

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from model_framework import MultiTaskLoRAModel
from data_processor import RiskProfilingDataProcessor
from evaluation import RiskProfilingEvaluator


def load_config(config_path: str = "../config/training_config.yaml"):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def main():
    """ä¸»å‡½æ•°"""
    
    # ç¤ºä¾‹ä¼ä¸šä¿¡æ¯
    sample_companies = [
        {
            "name": "åˆ›æ–°ç§‘æŠ€å…¬å¸",
            "info": "æŸäººå·¥æ™ºèƒ½åˆ›ä¸šå…¬å¸ï¼Œæˆç«‹äº2020å¹´ï¼Œä¸“æ³¨äºè®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ã€‚å…¬å¸æ‹¥æœ‰åšå£«å›¢é˜Ÿ15äººï¼Œç¡•å£«30äººï¼Œè·å¾—Aè½®èèµ„5000ä¸‡å…ƒã€‚ä¸»è¦äº§å“åŒ…æ‹¬æ™ºèƒ½å®¢æœç³»ç»Ÿå’Œå›¾åƒè¯†åˆ«APIï¼Œå·²æœåŠ¡500+ä¼ä¸šå®¢æˆ·ï¼Œå¹´è¥æ”¶3000ä¸‡å…ƒï¼ŒåŒæ¯”å¢é•¿150%ã€‚"
        },
        {
            "name": "ä¼ ç»Ÿåˆ¶é€ ä¼ä¸š", 
            "info": "æŸæ±½è½¦é›¶éƒ¨ä»¶åˆ¶é€ ä¼ä¸šï¼Œæˆç«‹äº1998å¹´ï¼Œæ³¨å†Œèµ„æœ¬2äº¿å…ƒã€‚ä¸»è¦ç”Ÿäº§å‘åŠ¨æœºé›¶éƒ¨ä»¶å’Œåˆ¹è½¦ç³»ç»Ÿï¼Œæ‹¥æœ‰å‘˜å·¥1200äººï¼Œå¹´äº§å€¼15äº¿å…ƒã€‚å®¢æˆ·åŒ…æ‹¬ä¸€æ±½ã€ä¸Šæ±½ç­‰ä¸»æœºå‚ï¼Œä½†å—æ–°èƒ½æºæ±½è½¦å†²å‡»ï¼Œä¼ ç»Ÿä¸šåŠ¡å¢é•¿æ”¾ç¼“ï¼Œæ­£åœ¨è½¬å‹å‡çº§ã€‚"
        },
        {
            "name": "é‡‘èæœåŠ¡æœºæ„",
            "info": "æŸåœ°æ–¹æ€§å•†ä¸šé“¶è¡Œï¼Œæˆç«‹äº2005å¹´ï¼Œæ³¨å†Œèµ„æœ¬50äº¿å…ƒã€‚ä¸»è¦ä¸šåŠ¡åŒ…æ‹¬ä¸ªäººé“¶è¡Œã€ä¼ä¸šé“¶è¡Œå’ŒæŠ•èµ„é“¶è¡Œã€‚æ‹¥æœ‰ç½‘ç‚¹200ä¸ªï¼Œå‘˜å·¥5000äººï¼Œèµ„äº§è§„æ¨¡2000äº¿å…ƒã€‚è¿‘å¹´æ¥åŠ å¤§é‡‘èç§‘æŠ€æŠ•å…¥ï¼Œæ¨å‡ºæ‰‹æœºé“¶è¡Œå’Œçº¿ä¸Šè´·æ¬¾äº§å“ã€‚"
        }
    ]
    
    print("ğŸš€ é£æ§ç”»åƒæ¨¡å‹æ¨ç†ç¤ºä¾‹")
    print("=" * 60)
    
    # 1. åŠ è½½é…ç½®
    print("ğŸ“‹ åŠ è½½é…ç½®...")
    config = load_config()
    
    # 2. åˆå§‹åŒ–æ¨¡å‹ï¼ˆè¿™é‡Œä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼Œå®é™…ä½¿ç”¨æ—¶åº”åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
    print("ğŸ¤– åˆå§‹åŒ–æ¨¡å‹...")
    model = MultiTaskLoRAModel(config)
    
    # æ³¨æ„ï¼šåœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæ‚¨éœ€è¦åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼š
    # model.load_model("./outputs/stage_3_full_scoring")
    
    # 3. åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨å’Œè¯„ä¼°å™¨
    data_processor = RiskProfilingDataProcessor(
        tokenizer=model.tokenizer,
        max_length=config['training']['max_seq_length']
    )
    
    evaluator = RiskProfilingEvaluator(
        tokenizer=model.tokenizer,
        dimensions=data_processor.all_dimensions
    )
    
    # 4. è¿›è¡Œæ¨ç†
    print("ğŸ” å¼€å§‹ä¼ä¸šè¯„ä¼°...")
    
    # é€‰æ‹©è¦è¯„ä¼°çš„ç»´åº¦
    target_dimensions = ["competitiveness", "innovation", "financial_health", "growth_potential"]
    
    for i, company in enumerate(sample_companies):
        print(f"\n--- è¯„ä¼°ä¼ä¸š {i+1}: {company['name']} ---")
        
        # åˆ›å»ºå¤šä»»åŠ¡prompt
        prompt = data_processor.create_multitask_prompt(
            company_info=company['info'],
            dimensions=target_dimensions,
            mode="inference"
        )
        
        print(f"ğŸ“ è¾“å…¥prompt:")
        print(f"{prompt[:200]}...")
        
        # ç”Ÿæˆè¯„ä¼°ç»“æœ
        print(f"â³ ç”Ÿæˆè¯„ä¼°ä¸­...")
        
        try:
            response = model.generate_response(
                prompt=prompt,
                max_new_tokens=1024,
                temperature=0.7,
                top_p=0.9
            )
            
            print(f"ğŸ“Š è¯„ä¼°ç»“æœ:")
            print(response)
            
            # æå–è¯„åˆ†
            scores = evaluator.extract_scores_from_response(response)
            
            print(f"\nğŸ¯ æå–çš„è¯„åˆ†:")
            for dim_key, score in scores.items():
                dim_name = data_processor.all_dimensions[dim_key]
                print(f"  {dim_name}: {score}/9")
            
            # è¯„ä¼°æ¨ç†è´¨é‡
            reasoning_quality = evaluator.extract_reasoning_quality(response)
            avg_quality = sum(reasoning_quality.values()) / len(reasoning_quality) if reasoning_quality else 0
            
            print(f"ğŸ“ˆ æ¨ç†è´¨é‡è¯„åˆ†: {avg_quality:.2f}/1.0")
            
        except Exception as e:
            print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        
        print("-" * 60)
    
    # 5. æ‰¹é‡è¯„ä¼°ç¤ºä¾‹
    print("\nğŸ”„ æ‰¹é‡è¯„ä¼°ç¤ºä¾‹")
    print("=" * 60)
    
    batch_results = []
    
    for company in sample_companies:
        # åˆ›å»ºprompt
        prompt = data_processor.create_multitask_prompt(
            company_info=company['info'],
            dimensions=target_dimensions,
            mode="inference"
        )
        
        try:
            # ç”Ÿæˆå›å¤
            response = model.generate_response(prompt, max_new_tokens=512, temperature=0.5)
            
            # æå–è¯„åˆ†
            scores = evaluator.extract_scores_from_response(response)
            
            batch_results.append({
                'company_name': company['name'],
                'scores': scores,
                'response': response
            })
            
        except Exception as e:
            print(f"æ‰¹é‡è¯„ä¼° {company['name']} å¤±è´¥: {e}")
    
    # 6. ç»“æœåˆ†æ
    print("ğŸ“ˆ æ‰¹é‡è¯„ä¼°ç»“æœåˆ†æ:")
    
    if batch_results:
        # åˆ›å»ºç»“æœè¡¨æ ¼
        import pandas as pd
        
        score_data = []
        for result in batch_results:
            row = {'ä¼ä¸šåç§°': result['company_name']}
            for dim_key, score in result['scores'].items():
                dim_name = data_processor.all_dimensions[dim_key]
                row[dim_name] = score
            score_data.append(row)
        
        df = pd.DataFrame(score_data)
        print(df.to_string(index=False))
        
        # ä¿å­˜ç»“æœ
        output_file = "inference_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(batch_results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # 7. è‡ªå®šä¹‰è¯„ä¼°ç¤ºä¾‹
    print("\nğŸ¨ è‡ªå®šä¹‰è¯„ä¼°ç¤ºä¾‹")
    print("=" * 60)
    
    # ç”¨æˆ·å¯ä»¥è¾“å…¥è‡ªå·±çš„ä¼ä¸šä¿¡æ¯
    custom_company_info = """
    æŸæ–°é›¶å”®ç”µå•†å¹³å°ï¼Œæˆç«‹äº2019å¹´ï¼Œä¸“æ³¨äºç”Ÿé²œé£Ÿå“é…é€ã€‚
    å…¬å¸é‡‡ç”¨"å‰ç½®ä»“+å³æ—¶é…é€"æ¨¡å¼ï¼Œåœ¨ä¸€äºŒçº¿åŸå¸‚å¸ƒå±€500ä¸ªå‰ç½®ä»“ã€‚
    æ‹¥æœ‰å‘˜å·¥2000äººï¼Œæ³¨å†Œç”¨æˆ·300ä¸‡ï¼Œæ—¥è®¢å•é‡10ä¸‡å•ã€‚
    å¹´GMVè¾¾åˆ°50äº¿å…ƒï¼Œä½†ç”±äºé…é€æˆæœ¬é«˜ï¼Œå°šæœªå®ç°ç›ˆåˆ©ã€‚
    è¿‘æœŸè·å¾—Bè½®èèµ„10äº¿å…ƒï¼Œè®¡åˆ’æ‰©å¤§å¸‚åœºè¦†ç›–å’Œæå‡è¿è¥æ•ˆç‡ã€‚
    """
    
    print("ğŸ“ è‡ªå®šä¹‰ä¼ä¸šä¿¡æ¯:")
    print(custom_company_info.strip())
    
    # å¯ä»¥é€‰æ‹©ç‰¹å®šç»´åº¦è¿›è¡Œè¯„ä¼°
    custom_dimensions = ["competitiveness", "innovation", "operational_efficiency", "financial_health"]
    
    prompt = data_processor.create_multitask_prompt(
        company_info=custom_company_info.strip(),
        dimensions=custom_dimensions,
        mode="inference"
    )
    
    try:
        response = model.generate_response(prompt, max_new_tokens=800, temperature=0.6)
        
        print("ğŸ¯ è¯„ä¼°ç»“æœ:")
        print(response)
        
        scores = evaluator.extract_scores_from_response(response)
        
        print("\nğŸ“Š è¯„åˆ†æ±‡æ€»:")
        for dim_key, score in scores.items():
            dim_name = data_processor.all_dimensions[dim_key]
            print(f"  {dim_name}: {score}/9")
        
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰è¯„ä¼°å¤±è´¥: {e}")
    
    print("\nâœ… æ¨ç†ç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¯·å…ˆåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹:")
    print("   model.load_model('./outputs/your_trained_model')")
    print("2. å¯ä»¥è°ƒæ•´generationå‚æ•°æ¥æ§åˆ¶è¾“å‡ºè´¨é‡")
    print("3. å»ºè®®å¯¹é‡è¦è¯„ä¼°è¿è¡Œå¤šæ¬¡å–å¹³å‡å€¼")
    print("4. å¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´è¯„ä¼°ç»´åº¦")


if __name__ == "__main__":
    main() 